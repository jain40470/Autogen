{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "ollama_model_client = OllamaChatCompletionClient(\n",
    "    model=\"llama3.2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "gemini_model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gemini-1.5-flash-8b\",\n",
    "    api_key=api_key \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "agentX = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=ollama_model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "agentY = AssistantAgent(\n",
    "    \"critic\" , \n",
    "    model_client=gemini_model_client,\n",
    "    system_message=\"Provide constructive feedback. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "\n",
    "text_termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "team = RoundRobinGroupChat([agentX , agentY], termination_condition=text_termination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 36, 45, 679793, tzinfo=datetime.timezone.utc), content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=41, completion_tokens=105), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 36, 50, 286924, tzinfo=datetime.timezone.utc), content=\"As summer's warmth begins to fade,\\nThe trees don vibrant hues displayed,\\nGolden, crimson, and amber bright,\\nA colorful canvas in the autumn light.\\n\\nThe air is crisp, the winds do blow,\\nLeaves rustle, swirling to and fro,\\nNature's final dance before winter's sleep,\\nA fleeting beauty, secrets keep.\\n\\nThe scent of woodsmoke wafts through air,\\nAs earthy smells and spices share,\\nThe forest floor, a carpet deep,\\nA crunchy blanket, soft and sweet to keep.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=141, completion_tokens=3), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 36, 52, 187904, tzinfo=datetime.timezone.utc), content='APPROVE\\n', type='TextMessage')] stop_reason=\"Text 'APPROVE' mentioned\"\n",
      "[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 36, 45, 679793, tzinfo=datetime.timezone.utc), content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=41, completion_tokens=105), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 36, 50, 286924, tzinfo=datetime.timezone.utc), content=\"As summer's warmth begins to fade,\\nThe trees don vibrant hues displayed,\\nGolden, crimson, and amber bright,\\nA colorful canvas in the autumn light.\\n\\nThe air is crisp, the winds do blow,\\nLeaves rustle, swirling to and fro,\\nNature's final dance before winter's sleep,\\nA fleeting beauty, secrets keep.\\n\\nThe scent of woodsmoke wafts through air,\\nAs earthy smells and spices share,\\nThe forest floor, a carpet deep,\\nA crunchy blanket, soft and sweet to keep.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=141, completion_tokens=3), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 36, 52, 187904, tzinfo=datetime.timezone.utc), content='APPROVE\\n', type='TextMessage')]\n"
     ]
    }
   ],
   "source": [
    "result = await team.run(task=\"Write a short poem about the fall season.\")\n",
    "print(result)\n",
    "print(result.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='user' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 5, 8, 36, 52, 201454, tzinfo=datetime.timezone.utc) content='Write a short poem about the fall season.' type='TextMessage'\n",
      "source='primary' models_usage=RequestUsage(prompt_tokens=41, completion_tokens=70) metadata={} created_at=datetime.datetime(2025, 7, 5, 8, 36, 55, 359931, tzinfo=datetime.timezone.utc) content=\"As summer's warmth begins to fade,\\nGolden leaves in whispers shade,\\nCrimson maples stand, ablaze with light,\\nAutumn's palette paints the night.\\n\\nThe air is crisp, the wind is cold,\\nNature's final dance, young and old,\\nFleeting moments of beauty rare,\\nA season's farewell, beyond compare.\" type='TextMessage'\n",
      "source='critic' models_usage=RequestUsage(prompt_tokens=101, completion_tokens=3) metadata={} created_at=datetime.datetime(2025, 7, 5, 8, 36, 55, 976370, tzinfo=datetime.timezone.utc) content='APPROVE\\n' type='TextMessage'\n",
      "messages=[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 36, 52, 201454, tzinfo=datetime.timezone.utc), content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=41, completion_tokens=70), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 36, 55, 359931, tzinfo=datetime.timezone.utc), content=\"As summer's warmth begins to fade,\\nGolden leaves in whispers shade,\\nCrimson maples stand, ablaze with light,\\nAutumn's palette paints the night.\\n\\nThe air is crisp, the wind is cold,\\nNature's final dance, young and old,\\nFleeting moments of beauty rare,\\nA season's farewell, beyond compare.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=101, completion_tokens=3), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 36, 55, 976370, tzinfo=datetime.timezone.utc), content='APPROVE\\n', type='TextMessage')] stop_reason=\"Text 'APPROVE' mentioned\"\n"
     ]
    }
   ],
   "source": [
    "await team.reset()  # Reset the team for a new task.\n",
    "# This method will clear the team’s state, including all agents. \n",
    "# It will call the each agent’s on_reset() method to clear the agent’s state.\n",
    "\n",
    "async for chunk in team.run_stream(task=\"Write a short poem about the fall season.\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing a Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='user' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 5, 8, 36, 55, 992652, tzinfo=datetime.timezone.utc) content='Write a short poem about the fall season.' type='TextMessage'\n",
      "source='primary' models_usage=RequestUsage(prompt_tokens=41, completion_tokens=103) metadata={} created_at=datetime.datetime(2025, 7, 5, 8, 37, 0, 449556, tzinfo=datetime.timezone.utc) content=\"As summer's warmth begins to fade,\\nThe earth awakens from its shade,\\nGolden leaves and crimson hue,\\nA fiery glow, both old and new.\\n\\nThe air is crisp, the winds do blow,\\nAnd nature's final dance begins to show,\\nThe trees stand tall, their branches bare,\\nA fleeting beauty, beyond compare.\\n\\nThe scent of woodsmoke fills the air,\\nAs earthy aromas waft with care,\\nThe stars appear in darkening sky,\\nAnd fall's sweet magic passes by.\" type='TextMessage'\n",
      "source='critic' models_usage=RequestUsage(prompt_tokens=137, completion_tokens=3) metadata={} created_at=datetime.datetime(2025, 7, 5, 8, 37, 1, 97017, tzinfo=datetime.timezone.utc) content='APPROVE\\n' type='TextMessage'\n",
      "Stop Reason: Text 'APPROVE' mentioned\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.base import TaskResult\n",
    "\n",
    "# When the team stops, it returns a TaskResult object with all the messages produced by the agents in the team.\n",
    "\n",
    "await team.reset()\n",
    "async for message in team.run_stream(task=\"Write a short poem about the fall season.\"):  # type: ignore\n",
    "    if isinstance(message, TaskResult):\n",
    "        print(\"Stop Reason:\", message.stop_reason)\n",
    "    else:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def work(x):\n",
    "    await asyncio.sleep(x)\n",
    "    return f\"Finished after {x} seconds\"\n",
    "\n",
    "# Run two tasks concurrently\n",
    "task1 = asyncio.create_task(work(2))\n",
    "task2 = asyncio.create_task(work(3))\n",
    "\n",
    "# Wait for both\n",
    "result1 = await task1\n",
    "result2 = await task2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a short poem about the fall season.\n",
      "---------- TextMessage (primary) ----------\n",
      "Amidst the trees, a colorful sight\n",
      "Golden hues and crimson bright\n",
      "The leaves fall slow, a gentle hue\n",
      "As nature's final dance begins anew\n",
      "\n",
      "The air is crisp, the winds do blow\n",
      "A time for change, as seasons go\n",
      "The earthy scent of fallen leaves\n",
      "Invigorates the senses, as autumn eaves\n",
      "\n",
      "The sun sets early, a fiery glow\n",
      "Painting the sky with shades of low\n",
      "A fleeting moment, pure and bright\n",
      "As fall's sweet magic takes its flight.\n",
      "---------- TextMessage (critic) ----------\n",
      "APPROVE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 4, 115836, tzinfo=datetime.timezone.utc), content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=41, completion_tokens=107), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 9, 4168, tzinfo=datetime.timezone.utc), content=\"Amidst the trees, a colorful sight\\nGolden hues and crimson bright\\nThe leaves fall slow, a gentle hue\\nAs nature's final dance begins anew\\n\\nThe air is crisp, the winds do blow\\nA time for change, as seasons go\\nThe earthy scent of fallen leaves\\nInvigorates the senses, as autumn eaves\\n\\nThe sun sets early, a fiery glow\\nPainting the sky with shades of low\\nA fleeting moment, pure and bright\\nAs fall's sweet magic takes its flight.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=130, completion_tokens=3), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 10, 925041, tzinfo=datetime.timezone.utc), content='APPROVE\\n', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "await team.reset() \n",
    "await Console(team.run_stream(task=\"Write a short poem about the fall season.\")) \n",
    "\n",
    "# team.run(...) is an awaitable coroutine.\n",
    "# team.run_stream(...) returns an async generator.e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopping the Team "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a short poem about the fall season.\n",
      "---------- TextMessage (primary) ----------\n",
      "Crimson leaves and amber light,\n",
      "Dance upon the autumn night.\n",
      "Golden hues and scarlet bright,\n",
      "A final flourish before winter's sight.\n",
      "\n",
      "The air is cool, the winds do sway,\n",
      "As nature's canvas ends its day.\n",
      "The scent of earth and woodsmoke sweet,\n",
      "Invigorates the senses to retreat.\n",
      "\n",
      "The sun sets early, a burning ember,\n",
      "Painting the sky with fiery splendor.\n",
      "A fleeting moment, pure and free,\n",
      "Autumn's beauty for you and me.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 10, 941917, tzinfo=datetime.timezone.utc), content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=166, completion_tokens=102), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 15, 931430, tzinfo=datetime.timezone.utc), content=\"Crimson leaves and amber light,\\nDance upon the autumn night.\\nGolden hues and scarlet bright,\\nA final flourish before winter's sight.\\n\\nThe air is cool, the winds do sway,\\nAs nature's canvas ends its day.\\nThe scent of earth and woodsmoke sweet,\\nInvigorates the senses to retreat.\\n\\nThe sun sets early, a burning ember,\\nPainting the sky with fiery splendor.\\nA fleeting moment, pure and free,\\nAutumn's beauty for you and me.\", type='TextMessage')], stop_reason='External termination requested')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.conditions import ExternalTermination\n",
    "import asyncio\n",
    "\n",
    "external_termination = ExternalTermination()\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    [agentX, agentY],\n",
    "    termination_condition=external_termination | text_termination,  # Use the bitwise OR operator to combine conditions.\n",
    ")\n",
    "\n",
    "# Run the team in a background task.\n",
    "run = asyncio.create_task(Console(team.run_stream(task=\"Write a short poem about the fall season.\")))\n",
    "\n",
    "# Wait for some time.\n",
    "await asyncio.sleep(0.1)\n",
    "\n",
    "# Stop the team.\n",
    "external_termination.set()\n",
    "\n",
    "# Wait for the team to finish.\n",
    "await run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asyncio.create_task(Console(team.run_stream(...)))\n",
    "\n",
    "# 1. \"Run the stream\"\n",
    "# 2. \"Pipe the output into Console()\"\n",
    "# 3. \"Do it without waiting immediately — I’ll await it when I’m ready\"\n",
    "# 4 .Then [await run] lets you pause and wait for it to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 15, 955803, tzinfo=datetime.timezone.utc), content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=41, completion_tokens=112), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 20, 971444, tzinfo=datetime.timezone.utc), content=\"As autumn leaves begin to sway,\\nGolden hues and crimson day,\\nThe trees stand tall, their branches wide,\\nA fiery spectacle, side by side.\\n\\nThe air is crisp, the wind is cold,\\nNature's final dance, before winter's fold,\\nThe scent of woodsmoke wafts through the air,\\nAs earthy aromas fill the autumn lair.\\n\\nThe sun sets early, days grow short,\\nFading light, a gentle, golden resort,\\nThe stars appear, like diamonds bright,\\nA night of rest, in autumn's silent night.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=147, completion_tokens=3), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 22, 821087, tzinfo=datetime.timezone.utc), content='APPROVE\\n', type='TextMessage')] stop_reason=\"Text 'APPROVE' mentioned\"\n",
      "[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 15, 955803, tzinfo=datetime.timezone.utc), content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=41, completion_tokens=112), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 20, 971444, tzinfo=datetime.timezone.utc), content=\"As autumn leaves begin to sway,\\nGolden hues and crimson day,\\nThe trees stand tall, their branches wide,\\nA fiery spectacle, side by side.\\n\\nThe air is crisp, the wind is cold,\\nNature's final dance, before winter's fold,\\nThe scent of woodsmoke wafts through the air,\\nAs earthy aromas fill the autumn lair.\\n\\nThe sun sets early, days grow short,\\nFading light, a gentle, golden resort,\\nThe stars appear, like diamonds bright,\\nA night of rest, in autumn's silent night.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=147, completion_tokens=3), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 22, 821087, tzinfo=datetime.timezone.utc), content='APPROVE\\n', type='TextMessage')]\n"
     ]
    }
   ],
   "source": [
    "await team.reset()\n",
    "\n",
    "task = asyncio.create_task(team.run(task=\"Write a short poem about the fall season.\"))\n",
    "result = await task\n",
    "\n",
    "print(result)\n",
    "print(result.messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a short poem about the fall season.\n",
      "---------- TextMessage (primary) ----------\n",
      "As summer's warmth begins to fade,\n",
      "The trees don crimson, golden shade,\n",
      "Their leaves, a rustling whisper low,\n",
      "A symphony of autumn's woe.\n",
      "\n",
      "The air is crisp, the winds do blow,\n",
      "And nature's final dance begins to show,\n",
      "The forest floor, a carpet deep,\n",
      "Of orange, red, and yellow sleep.\n",
      "\n",
      "The scent of woodsmoke fills the air,\n",
      "As earthy aromas waft with care,\n",
      "A season's farewell, a story told,\n",
      "Of autumn's beauty, young and old.\n",
      "---------- TextMessage (critic) ----------\n",
      "APPROVE\n",
      "\n",
      "---------- TextMessage (user) ----------\n",
      "Write a short poem about the fall season.\n",
      "---------- TextMessage (primary) ----------\n",
      "As autumn leaves begin to sway,\n",
      "Golden hues and crimson stay,\n",
      "A fleeting dance, a final spin,\n",
      "Before the winter's chill within.\n",
      "\n",
      "The air is crisp, the winds do blow,\n",
      "Scents of woodsmoke start to flow,\n",
      "Nature's canvas, painted bright,\n",
      "A colorful farewell to the light.\n",
      "---------- TextMessage (critic) ----------\n",
      "APPROVE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 28, 340856, tzinfo=datetime.timezone.utc), content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=41, completion_tokens=63), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 31, 88667, tzinfo=datetime.timezone.utc), content=\"As autumn leaves begin to sway,\\nGolden hues and crimson stay,\\nA fleeting dance, a final spin,\\nBefore the winter's chill within.\\n\\nThe air is crisp, the winds do blow,\\nScents of woodsmoke start to flow,\\nNature's canvas, painted bright,\\nA colorful farewell to the light.\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=96, completion_tokens=3), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 37, 31, 631836, tzinfo=datetime.timezone.utc), content='APPROVE\\n', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use await directly:\n",
    "# When you want the result right away\n",
    "# No other tasks need to run in parallel\n",
    "\n",
    "await team.reset()\n",
    "await Console(team.run_stream(task=\"Write a short poem about the fall season.\"))  # Waits till done before moving forward\n",
    "\n",
    "# Use asyncio.create_task():\n",
    "# When you want to start a task in the background\n",
    "# Do other things before waiting\n",
    "# Handle multiple tasks concurrently\n",
    "\n",
    "await team.reset()\n",
    "task = asyncio.create_task(Console(team.run_stream(task=\"Write a short poem about the fall season.\")))\n",
    "# do something else...\n",
    "await task  # Now wait for it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming in a Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (primary) ----------\n",
      "I'm glad you liked it! If you have any other requests or need help with anything else, feel free to ask!\n",
      "---------- TextMessage (critic) ----------\n",
      "I'm ready for your next request!  Let's see what you'd like to do.\n",
      "\n",
      "---------- TextMessage (primary) ----------\n",
      "I'd love to create a short story for you. Do you have any specific prompts or themes in mind, or would you like me to come up with something entirely random?\n",
      "\n",
      "Also, is there a particular tone or style you'd like the story to convey? For example, would you like it to be:\n",
      "\n",
      "* Light-hearted and humorous\n",
      "* Dark and mysterious\n",
      "* Adventurous and action-packed\n",
      "* Heartwarming and sentimental\n",
      "\n",
      "Let me know, and I'll get started!\n",
      "---------- TextMessage (critic) ----------\n",
      "I'd like a short story, approximately 500 words, that is **light-hearted and humorous**.  The story should involve **animals** and their interactions with **humanity**, focusing on a relatable and slightly absurd situation.  Think a bit like a whimsical, slightly absurd Aesop's Fable, but with a modern twist.  Let your imagination run wild!\n",
      "\n",
      "---------- TextMessage (primary) ----------\n",
      "In the heart of the city, there existed a peculiar café, aptly named \"The Cozy Cup.\" It was a haven for humans and animals alike, where the air was sweet with the scent of freshly brewed coffee and baked goods. The café's proprietor, a kind-hearted woman named Emma, had an unusual policy: she believed that all creatures, great and small, deserved equal rights to enjoy her establishment.\n",
      "\n",
      "One sunny morning, as Emma was prepping for the day's customers, a most unlikely duo walked into the café. There was Rufus, a charismatic raccoon with a penchant for disco music and platform shoes, and his best friend, Bertrand, a bespectacled cat with a Ph.D. in astrophysics.\n",
      "\n",
      "Rufus, resplendent in his sparkly jumpsuit, demanded to know why Emma hadn't yet upgraded the café's Wi-Fi to accommodate his feline friend's advanced internet needs. \"Bertrand here is trying to connect to the Galactic Guide to Feline Space Travel,\" Rufus explained, \"and your router is woefully inadequate.\"\n",
      "\n",
      "Emma smiled and said, \"Oh dear, I didn't realize we were in need of a cat-savant-approved internet plan.\" She scribbled some notes on a napkin and set off to find a solution.\n",
      "\n",
      "As she returned with a shiny new router, Bertrand began explaining the intricacies of wormhole stabilization to Rufus. Meanwhile, a curious squirrel named Nutmeg scampered onto Emma's lap, chattering excitedly about the upcoming Acorn Festival.\n",
      "\n",
      "Just then, the café door swung open, and in walked Dr. Lee, a renowned animal psychologist with a passion for puns. \"Ah, Emma, I hear you've got a feline astrophysicist on your hands,\" he said with a grin. \"Fur-get about it; Bertrand's got his paws on the stars!\"\n",
      "\n",
      "Bertrand shot back, \"You think a simple pun will distract me from the existential crises of wormhole theory? Think again, Doc.\"\n",
      "\n",
      "As the morning wore on, the café became a hub of zany animal antics and witty banter. Emma served coffee to Rufus in a glittery mug, while Bertrand sipped from a miniature telescope-print cup.\n",
      "\n",
      "Just as things were settling down, a harried-looking woman rushed in, clutching her smartphone. \"I've lost my dog!\" she wailed. \"He's been tracking me on social media for weeks, and now he's gone dark!\"\n",
      "\n",
      "Rufus, ever the party animal, offered his expertise: \"Dude, you gotta get your pup to Instagram more often.\" Bertrand chimed in, \"Actually, it's a classic case of Feline- human Disconnect – we need to establish better online boundaries.\"\n",
      "\n",
      "Emma intervened, saying, \"Don't worry, dear; I'll help you track down your furry friend. But first, let me ask: have you considered the existential implications of our internet addiction on our relationships with our pets?\"\n",
      "\n",
      "As they searched for the lost dog, Emma's team of animal experts (Rufus, Bertrand, Nutmeg, and a wise-cracking parrot named Polly) led the charge. They scoured the city, asking the universe (and various coffee cups) for clues.\n",
      "\n",
      "Finally, they tracked down the wayward pup to a nearby park, where he was busy streaming dog-friendly cat videos on his human's phone. The reunion was joyous, with Rufus and Bertrand offering sage advice: \"Never underestimate the power of a good Wi-Fi signal – or a really entertaining video.\"\n",
      "\n",
      "As the sun set over The Cozy Cup, Emma smiled at her eclectic team. \"You know, I think we've stumbled upon something truly special here. A café where humans and animals can come together, share laughs, and learn a thing or two from each other.\"\n",
      "\n",
      "And so, in this whimsical world of coffee-fueled conversations and animal camaraderie, The Cozy Cup continued to thrive – a testament to the power of laughter, friendship, and an open Wi-Fi network.\n",
      "---------- TextMessage (critic) ----------\n",
      "APPROVE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=117, completion_tokens=26), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 55, 22, 354373, tzinfo=datetime.timezone.utc), content=\"I'm glad you liked it! If you have any other requests or need help with anything else, feel free to ask!\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=125, completion_tokens=23), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 55, 24, 553847, tzinfo=datetime.timezone.utc), content=\"I'm ready for your next request!  Let's see what you'd like to do.\\n\", type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=171, completion_tokens=98), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 55, 29, 135320, tzinfo=datetime.timezone.utc), content=\"I'd love to create a short story for you. Do you have any specific prompts or themes in mind, or would you like me to come up with something entirely random?\\n\\nAlso, is there a particular tone or style you'd like the story to convey? For example, would you like it to be:\\n\\n* Light-hearted and humorous\\n* Dark and mysterious\\n* Adventurous and action-packed\\n* Heartwarming and sentimental\\n\\nLet me know, and I'll get started!\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=251, completion_tokens=79), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 55, 30, 141171, tzinfo=datetime.timezone.utc), content=\"I'd like a short story, approximately 500 words, that is **light-hearted and humorous**.  The story should involve **animals** and their interactions with **humanity**, focusing on a relatable and slightly absurd situation.  Think a bit like a whimsical, slightly absurd Aesop's Fable, but with a modern twist.  Let your imagination run wild!\\n\", type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=356, completion_tokens=834), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 56, 10, 218656, tzinfo=datetime.timezone.utc), content='In the heart of the city, there existed a peculiar café, aptly named \"The Cozy Cup.\" It was a haven for humans and animals alike, where the air was sweet with the scent of freshly brewed coffee and baked goods. The café\\'s proprietor, a kind-hearted woman named Emma, had an unusual policy: she believed that all creatures, great and small, deserved equal rights to enjoy her establishment.\\n\\nOne sunny morning, as Emma was prepping for the day\\'s customers, a most unlikely duo walked into the café. There was Rufus, a charismatic raccoon with a penchant for disco music and platform shoes, and his best friend, Bertrand, a bespectacled cat with a Ph.D. in astrophysics.\\n\\nRufus, resplendent in his sparkly jumpsuit, demanded to know why Emma hadn\\'t yet upgraded the café\\'s Wi-Fi to accommodate his feline friend\\'s advanced internet needs. \"Bertrand here is trying to connect to the Galactic Guide to Feline Space Travel,\" Rufus explained, \"and your router is woefully inadequate.\"\\n\\nEmma smiled and said, \"Oh dear, I didn\\'t realize we were in need of a cat-savant-approved internet plan.\" She scribbled some notes on a napkin and set off to find a solution.\\n\\nAs she returned with a shiny new router, Bertrand began explaining the intricacies of wormhole stabilization to Rufus. Meanwhile, a curious squirrel named Nutmeg scampered onto Emma\\'s lap, chattering excitedly about the upcoming Acorn Festival.\\n\\nJust then, the café door swung open, and in walked Dr. Lee, a renowned animal psychologist with a passion for puns. \"Ah, Emma, I hear you\\'ve got a feline astrophysicist on your hands,\" he said with a grin. \"Fur-get about it; Bertrand\\'s got his paws on the stars!\"\\n\\nBertrand shot back, \"You think a simple pun will distract me from the existential crises of wormhole theory? Think again, Doc.\"\\n\\nAs the morning wore on, the café became a hub of zany animal antics and witty banter. Emma served coffee to Rufus in a glittery mug, while Bertrand sipped from a miniature telescope-print cup.\\n\\nJust as things were settling down, a harried-looking woman rushed in, clutching her smartphone. \"I\\'ve lost my dog!\" she wailed. \"He\\'s been tracking me on social media for weeks, and now he\\'s gone dark!\"\\n\\nRufus, ever the party animal, offered his expertise: \"Dude, you gotta get your pup to Instagram more often.\" Bertrand chimed in, \"Actually, it\\'s a classic case of Feline- human Disconnect – we need to establish better online boundaries.\"\\n\\nEmma intervened, saying, \"Don\\'t worry, dear; I\\'ll help you track down your furry friend. But first, let me ask: have you considered the existential implications of our internet addiction on our relationships with our pets?\"\\n\\nAs they searched for the lost dog, Emma\\'s team of animal experts (Rufus, Bertrand, Nutmeg, and a wise-cracking parrot named Polly) led the charge. They scoured the city, asking the universe (and various coffee cups) for clues.\\n\\nFinally, they tracked down the wayward pup to a nearby park, where he was busy streaming dog-friendly cat videos on his human\\'s phone. The reunion was joyous, with Rufus and Bertrand offering sage advice: \"Never underestimate the power of a good Wi-Fi signal – or a really entertaining video.\"\\n\\nAs the sun set over The Cozy Cup, Emma smiled at her eclectic team. \"You know, I think we\\'ve stumbled upon something truly special here. A café where humans and animals can come together, share laughs, and learn a thing or two from each other.\"\\n\\nAnd so, in this whimsical world of coffee-fueled conversations and animal camaraderie, The Cozy Cup continued to thrive – a testament to the power of laughter, friendship, and an open Wi-Fi network.', type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=1159, completion_tokens=3), metadata={}, created_at=datetime.datetime(2025, 7, 5, 8, 56, 12, 231691, tzinfo=datetime.timezone.utc), content='APPROVE\\n', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream())# Resume the team to continue the last task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aborting a Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task was cancelled.\n"
     ]
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "# Use another coroutine to run the team.\n",
    "await team.reset()\n",
    "run = asyncio.create_task(\n",
    "    team.run(\n",
    "        task=\"Translate the poem to Spanish.\",\n",
    "        cancellation_token=cancellation_token,\n",
    "    )\n",
    ")\n",
    "\n",
    "cancellation_token.cancel()\n",
    "# It is used to programmatically cancel the ongoing team.run(...) task.\n",
    "\n",
    "try:\n",
    "    result = await run  # This will raise a CancelledError.\n",
    "except asyncio.CancelledError:\n",
    "    print(\"Task was cancelled.\")\n",
    "\n",
    "# Different from stopping a team, aborting a team will immediately stop the team \n",
    "# and raise a CancelledError exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 5, 9, 3, 4, 227296, tzinfo=datetime.timezone.utc), content='Hey how are you', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=36, completion_tokens=65), metadata={}, created_at=datetime.datetime(2025, 7, 5, 9, 3, 7, 126687, tzinfo=datetime.timezone.utc), content=\"I'm doing well, thank you for asking! I'm a large language model, so I don't have emotions or feelings in the way that humans do, but I'm always happy to chat and help with any questions or topics you'd like to discuss. How about you? How's your day going so far?\", type='TextMessage')] stop_reason='The group chat is stopped.'\n"
     ]
    }
   ],
   "source": [
    "cancellation_token2 = CancellationToken()\n",
    "\n",
    "await team.reset()\n",
    "\n",
    "run = asyncio.create_task(\n",
    "    team.run(\n",
    "        task=\"Hey how are you\",\n",
    "        cancellation_token=cancellation_token2,\n",
    "    )\n",
    ")\n",
    "\n",
    "result = await run\n",
    "print(result)\n",
    "\n",
    "# if you use the same cancellation token then it will not work and give error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here\n",
      "Message: source='user' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 5, 9, 6, 13, 44610, tzinfo=datetime.timezone.utc) content='Translate the poem to Spanish.' type='TextMessage'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for primary_6565807a-cd73-468c-8584-621438174dae/6565807a-cd73-468c-8584-621438174dae\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/autogen_core/_single_threaded_agent_runtime.py\", line 605, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/autogen_core/_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 67, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/autogen_core/_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/autogen_core/_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 79, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py\", line 852, in on_messages_stream\n",
      "    async for inference_output in self._call_llm(\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py\", line 981, in _call_llm\n",
      "    model_result = await model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/autogen_ext/models/ollama/_ollama_client.py\", line 628, in create\n",
      "    result: ChatResponse = await future\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/ollama/_client.py\", line 854, in chat\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/ollama/_client.py\", line 692, in _request\n",
      "    return cls(**(await self._request_raw(*args, **kwargs)).json())\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/ollama/_client.py\", line 632, in _request_raw\n",
      "    r = await self._client.request(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpx/_client.py\", line 1540, in request\n",
      "    return await self.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpx/_client.py\", line 1629, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/akashjain/Desktop/Autogen/AutoGenv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancelling the task now...\n",
      "Task was cancelled.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "async def run_and_cancel_after_delay():\n",
    "\n",
    "    cancellation_token = CancellationToken()\n",
    "\n",
    "    await team.reset()\n",
    "\n",
    "    # Start running the team with run_stream\n",
    "    run_stream = team.run_stream(\n",
    "        task=\"Translate the poem to Spanish.\",\n",
    "        cancellation_token=cancellation_token,\n",
    "    )\n",
    "\n",
    "    # Create an async task to iterate messages from run_stream\n",
    "    async def consume_stream():\n",
    "        async for message in run_stream:\n",
    "            print(\"Message:\", message)\n",
    "\n",
    "    consumer_task = asyncio.create_task(consume_stream())\n",
    "\n",
    "    # Wait for 3 seconds before cancelling\n",
    "    await asyncio.sleep(3)\n",
    "\n",
    "    print(\"Cancelling the task now...\")\n",
    "    cancellation_token.cancel()\n",
    "\n",
    "    try:\n",
    "        await consumer_task\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"Task was cancelled.\")\n",
    "\n",
    "# Run the async function\n",
    "await run_and_cancel_after_delay()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoGenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
